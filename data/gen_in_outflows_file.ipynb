{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Inflow and Outflow Files\n",
    "Use this file to generate inflows and outflows file based on LAKE input meteorology file. There are multiple ways to specify inflows and outflows in LAKE. This notebook generates inflow/outflow files that are not discretized by depth and have one input row per day.\n",
    "\n",
    "##### Parameterization required for input/output files.\n",
    "\n",
    "setup.dat\n",
    "\n",
    "* tribheat 2 # inflow/outflow file format, we will use format 2 (inflows not by depth, varying once per day)\n",
    "\n",
    "* N_tribin 1 # This and the following line define number of tributaries\n",
    "\n",
    "    1\n",
    "* N_triblev 1 # tributary layers, we are only specifying one layer for the entire water column\n",
    "* fileinflow  'YKD-burned-inflows_inflows.dat'\n",
    "* fileoutflow 'YKD-burned-inflows_outflows.dat'\n",
    "* iefflloc 1\n",
    "* dttribupdate 1. #timestep (days) for tributary update\n",
    "\n",
    "for tribheat 2, column order is:\n",
    "\n",
    "* 'Date', 'width', 'discharge velocity', 'temp', 'sal', 'Ux', 'Uy', 'DOC', 'POC', 'DIC', 'CH4', 'O2'\n",
    "\n",
    "order of outflows columns is:\n",
    "* 'Date', 'width', discharge velocity\n",
    "\n",
    "\n",
    "units are width (m), velocity (m/s), temp (C), sal (?), Ux (?), Uy(?), DOC (mol/m3), POC (mol/m3), DIC (mol/m3), CH4 (mol/m3), O2 (mol/m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_meteo_file = '/home/amullen/LAKE/meteo/YKD-burned-inflows.dat'\n",
    "path_to_inflows = '/home/amullen/LAKE/meteo/YKD-burned-inflows_inflows.dat'\n",
    "path_to_outflows = '/home/amullen/LAKE/meteo/YKD-burned-inflows_outflows.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_df = pd.read_csv(path_to_meteo_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inflows\n",
    "\n",
    "inflows_df = pd.DataFrame(columns=['Date', 'width', 'U', 'temp', 'sal', 'Ux', 'Uy', 'DOC', 'POC', 'DIC', 'CH4', 'O2']) #for tribheat=2\n",
    "inflows_df['Date'] = pd.to_datetime(meteo_df[['Year', 'Month', 'Day']]).dt.strftime('%d%m%Y')\n",
    "inflows_df = inflows_df.fillna(-999)\n",
    "\n",
    "#only required columns are 'width' and 'U', everything not given a real value should be -999\n",
    "inflows_df['width'] = 32 #TKL873: 90\n",
    "inflows_df['U'] = ((4.3 * 1e-2)/86400) #m/s Dabrowski et al., 2020\n",
    "inflows_df['CH4'] = 0.370 #mol/m3, Dabrowski et al., 2020 YKD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outflows\n",
    "\n",
    "outflows_df = pd.DataFrame(columns=['Date', 'width', 'U'])\n",
    "outflows_df['Date'] = inflows_df['Date']\n",
    "outflows_df['width'] = inflows_df['width']\n",
    "outflows_df['U'] = inflows_df['U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflows_df.to_csv(path_to_inflows, index=False, header=False)\n",
    "outflows_df.to_csv(path_to_outflows, index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lake_modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
